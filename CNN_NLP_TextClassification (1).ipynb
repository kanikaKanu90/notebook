{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_NLP_TextClassification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20WaoJnQ3Jpx"
      },
      "source": [
        "## Exercise 3 - Language Identification -Reloaded and Convoluted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79dccq9UzSUL"
      },
      "source": [
        "\n",
        "#Importing the tools\n",
        "import csv\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F751peA-3T9s"
      },
      "source": [
        "\n",
        "Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRoE3MrNZOyP"
      },
      "source": [
        "url_train_dev = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTOZ2rC82rhNsJduoyKYTsVeH6ukd7Bpxvxn_afOibn3R-eadZGXu82eCU9IRpl4CK_gefEGsYrA_oM/pub?gid=1863430984&single=true&output=tsv'\n",
        "url_test = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vT-KNR9nuYatLkSbzSRgpz6Ku1n4TN4w6kKmFLkA6QJHTfQzmX0puBsLF7PAAQJQAxUpgruDd_RRgK7/pub?gid=417546901&single=true&output=tsv'"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMDCE4Km3d4K"
      },
      "source": [
        "Splitting the data into tweet and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li6RIPkiZYMh"
      },
      "source": [
        "\n",
        "from io import StringIO\n",
        "import requests\n",
        "\n",
        "def load_dataset(url):\n",
        "    r = requests.get(url)\n",
        "    data = r.content.decode('utf8')\n",
        "    df = pd.read_csv(StringIO(data), sep='\\t')\n",
        "    df.columns = ['tweet', 'label']\n",
        "    return df\n",
        "    "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtpP57DAZfhr",
        "outputId": "27091eb8-2d6e-46c5-fec8-863d30780376",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_train  = load_dataset(url_train_dev)\n",
        "df_test = load_dataset(url_test)\n",
        "print(df_train[0:10])\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                               tweet label\n",
            "0  يا من أناديها ويخنقني البكاء  ويكاد صمت الدمع ...    ar\n",
            "1  فيه فرق بين اهل غزة اللى مطحونين من ناحيتين وب...    ar\n",
            "2  ﻋﻦ ﺍﻟﻠﺤﻈﺔ اﻟﺤﻠﻮﺓﺓ ﺍﻟﻠﻲ ﺑﺘﻐﻤﺾ ﻓﻴﻬﺎ ﻋﻴﻨﻴﻚ ﺑﺘﻔﻜﺮ ...    ar\n",
            "3                                  يا ابو سلو عرفتني    ar\n",
            "4  ب50 ريال أكفل معتمر في رمضان ، ولك بإذن الله م...    ar\n",
            "5  توجيه كيفية تثبيت البرامج الثابتة ROM التحميل ...    ar\n",
            "6  {وأنه هو أغنى وأقنى} [النجم:48] http://t.co/is...    ar\n",
            "7  اللهم قدر لنا الفرح بكل اشكاله ، انت الكريم ال...    ar\n",
            "8  #غزه_تحت_القصف  داعش أخواني حيل عندكم بالمدنيي...    ar\n",
            "9  {يعلمون ظاهرا من الحياة الدنيا وهم عن الآخرة ه...    ar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDHUPsvA3mnT"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wCuI6Z0i0hO"
      },
      "source": [
        "#Converting all the tweets to lower string\n",
        "df_train[\"tweet\"] = df_train[\"tweet\"].str.lower()\n",
        "filter_dt=df_train.groupby('label').count()['tweet']\n",
        "\n",
        "#Removing all tweets with less than 15 samples to train from \n",
        "filter_dt=filter_dt.loc[filter_dt.values>15].index\n",
        "df_train=df_train[df_train['label'].isin(filter_dt)]\n",
        "df_train.reset_index(inplace=True)\n",
        "filter_dt=df_train.groupby('label').count()['tweet']\n",
        "\n",
        "#Removing all labels from test which are not there in training\n",
        "df_test=df_test[df_test['label'].isin(df_train.label.unique())]\n",
        "df_test.reset_index(inplace=True)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "web4bUhzbyPU",
        "outputId": "8ccf2078-555a-40d4-c969-8dccc0893dfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 52460 entries, 0 to 52459\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   index   52460 non-null  int64 \n",
            " 1   tweet   52460 non-null  object\n",
            " 2   label   52460 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 1.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAZRzNgGdxQQ",
        "outputId": "03b6c215-524a-43b9-9df7-fef8a0cfa06c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>يا من أناديها ويخنقني البكاء  ويكاد صمت الدمع ...</td>\n",
              "      <td>ar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>فيه فرق بين اهل غزة اللى مطحونين من ناحيتين وب...</td>\n",
              "      <td>ar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ﻋﻦ ﺍﻟﻠﺤﻈﺔ اﻟﺤﻠﻮﺓﺓ ﺍﻟﻠﻲ ﺑﺘﻐﻤﺾ ﻓﻴﻬﺎ ﻋﻴﻨﻴﻚ ﺑﺘﻔﻜﺮ ...</td>\n",
              "      <td>ar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>يا ابو سلو عرفتني</td>\n",
              "      <td>ar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>ب50 ريال أكفل معتمر في رمضان ، ولك بإذن الله م...</td>\n",
              "      <td>ar</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                                              tweet label\n",
              "0      0  يا من أناديها ويخنقني البكاء  ويكاد صمت الدمع ...    ar\n",
              "1      1  فيه فرق بين اهل غزة اللى مطحونين من ناحيتين وب...    ar\n",
              "2      2  ﻋﻦ ﺍﻟﻠﺤﻈﺔ اﻟﺤﻠﻮﺓﺓ ﺍﻟﻠﻲ ﺑﺘﻐﻤﺾ ﻓﻴﻬﺎ ﻋﻴﻨﻴﻚ ﺑﺘﻔﻜﺮ ...    ar\n",
              "3      3                                  يا ابو سلو عرفتني    ar\n",
              "4      4  ب50 ريال أكفل معتمر في رمضان ، ولك بإذن الله م...    ar"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVBZBK_id1mH",
        "outputId": "88b264b3-1fcc-4dac-ab54-e3a3ecff1a89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_train.label.unique()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ar', 'ca', 'de', 'el', 'en', 'es', 'fa', 'fr', 'he', 'hi', 'id',\n",
              "       'it', 'ja', 'ko', 'ms', 'nl', 'pl', 'pt', 'ru', 'sr', 'sv', 'th',\n",
              "       'tl', 'tr', 'uk', 'und', 'vi', 'zh-CN'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE_P7qH64A5r"
      },
      "source": [
        "Retrieving the tweets and labels from the training and the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1kckFNrR4xl",
        "outputId": "c3b1cb80-83af-4a25-8894-e90086353158",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train = df_train.tweet\n",
        "y_train = df_train.label\n",
        "X_test = df_test.tweet\n",
        "y_test = df_test.label\n",
        "\n",
        "print('Training tweet shape: ', X_train.shape)\n",
        "print('Training labels shape: ', y_train.shape)\n",
        "print('Test tweet shape: ', X_test.shape)\n",
        "print('Test labels shape: ', y_test.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training tweet shape:  (52460,)\n",
            "Training labels shape:  (52460,)\n",
            "Test tweet shape:  (13217,)\n",
            "Test labels shape:  (13217,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lF_AYCZ4LH4"
      },
      "source": [
        "Data Cleaning - removing all the unnecessary data from the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaNT0WGT7apG",
        "outputId": "aaf625b6-7723-4a73-d32a-149069c007dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def preprocessor(text):\n",
        "  \n",
        "  text = re.sub(r\"http\\S+\", \"\", text)       ##Removing URL\n",
        "  text = re.sub('@[^\\s]+','',text)          ##Removing @Username\n",
        "  text = re.sub('[\\W]+', ' ', text.lower()) ##Removing NonCharacter eg.emojis\n",
        "  text = re.sub('<[^>]*>', '', text)        ##Removing entire HTML\n",
        "  text = re.sub(r'[0-9]+', '', text)        ## Removing numbers\n",
        "  \n",
        "  return text\n",
        "\n",
        "#Applying the text cleaning to the train data\n",
        "X_train = X_train.apply(preprocessor)\n",
        "X_train[0:30] #Checking the data "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     يا من أناديها ويخنقني البكاء ويكاد صمت الدمع أ...\n",
              "1     فيه فرق بين اهل غزة اللى مطحونين من ناحيتين وب...\n",
              "2     ﻋﻦ ﺍﻟﻠﺤﻈﺔ اﻟﺤﻠﻮﺓﺓ ﺍﻟﻠﻲ ﺑﺘﻐﻤﺾ ﻓﻴﻬﺎ ﻋﻴﻨﻴﻚ ﺑﺘﻔﻜﺮ ...\n",
              "3                                     يا ابو سلو عرفتني\n",
              "4     ب ريال أكفل معتمر في رمضان ولك بإذن الله مثل أ...\n",
              "5     توجيه كيفية تثبيت البرامج الثابتة rom التحميل ...\n",
              "6                            وأنه هو أغنى وأقنى النجم  \n",
              "7     اللهم قدر لنا الفرح بكل اشكاله انت الكريم الذي...\n",
              "8      غزه_تحت_القصف داعش أخواني حيل عندكم بالمدنيين...\n",
              "9      يعلمون ظاهرا من الحياة الدنيا وهم عن الآخرة ه...\n",
              "10               افضل كتاب قرأته هو أمي ابراهام لنكولن \n",
              "11    ولأن ه م م لائ ك ة ص غار ن ع ش ق ات كاءة رؤوس ...\n",
              "12        خ لاصة الح ب هي ت فكر بقلبهآ وهو ي فكر بعقله \n",
              "13    جميل آن يفهمك من تحبب ويخآف عليك و يغآر عليكك ...\n",
              "14    حتى الندم على المعصيه تؤجر عليه سبحانك يالله م...\n",
              "15     اها يا بيبي والله اتهرست علي تويتر و ع الفيس ...\n",
              "16     لا يقاتلونكم جميعا إلا في قرى محصنة أو من ورا...\n",
              "17          طبت منك نهائيا بس كلي رجاء ما ترجع من جديد \n",
              "18     وإن تجهر بالقول فإنه يعلم السر وأخفى طه  تطبي...\n",
              "19                                                  الو\n",
              "20             داعش يصلب سوريا  ساعات وهو حي داعش syria\n",
              "21    ﺧﻟك ﻋزﯾز آﻟﻧﻓس ﻟۈ ﮪﻣۈﻣك ﺟﺑآللاﭠﺷﺷﮐي ﻟﻟﻧآﺳس ﻣن ...\n",
              "22    اللهم أفرح قلبي وقلب من أحب وأغسل أحزاننا وهمو...\n",
              "23    اللهم أحسن عاقبتنا في الأمور كلها وأجرنا من خز...\n",
              "24     سيدي إيفني شكاية أجنبي بدرك ميرلفت يحرك فرقة ...\n",
              "25     الصوره هاذي الله يسلمك في اسبانبا غير صحيح ان...\n",
              "26                             انتظري اجل خيره لك يارب \n",
              "27               اللهم اسعد امي كما تسعدني و احفظها لي \n",
              "28     إن الذين كفروا من أهل الكتاب والمشركين في نار...\n",
              "29    اللهم أعز الإسلآم والمسلمين اللهم زلزل الأرض م...\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqhdA7Zw4bs6"
      },
      "source": [
        "Checking the shape and assigning new variables to train and test data to be used for further processing of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K1zxZpT1r_y",
        "outputId": "c4d12724-e93d-426d-f312-3d95773f6cfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "X_train_n = X_train\n",
        "y_train_n = y_train\n",
        "X_test_n = X_test\n",
        "y_test_n = y_test\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(52460,)\n",
            "(52460,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTcwd_to42wL"
      },
      "source": [
        "Preparing the final data for the model\n",
        "\n",
        "\n",
        "1.   Tokenizing text data\n",
        "2.   Encoding labels\n",
        "3.   Finding the maximum length of the data and vocab size  for the input shape of the model input layer\n",
        "4.   Printing the details\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycPjJbdy2qvj",
        "outputId": "de479ff3-dae5-43a4-da62-41adf8c1e42f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer                    \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout,MaxPooling1D, Conv1D, Flatten , Embedding\n",
        "from keras.preprocessing import text, sequence\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "from keras import utils\n",
        "\n",
        "#Calulating the length of the doc to be fed into the input layer of the model\n",
        "def maxilen(lines):\n",
        "\treturn max([len(s.split()) for s in lines])\n",
        "\n",
        "#Fitting the dataTokenizer\n",
        "def Generatetokenizer(lines):\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        "\n",
        "#Creating the tokenizer\n",
        "tokenizer = Generatetokenizer(X_train_n[0:])\n",
        "\n",
        "#Encoding Text\n",
        "def text_encoder(tokenizer, lines, length):\n",
        "\t\n",
        "\tencoded = tokenizer.texts_to_sequences(lines)\n",
        "\tpadded = pad_sequences(encoded, maxlen=length, padding='post')\n",
        "\treturn padded\n",
        "\n",
        "#Calculating the maximum document length for the input shape for the model input\n",
        "length = maxilen(X_train_n[0:])\n",
        "\n",
        "#Calculating the vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "print('Maximum document length: %d' % length)\n",
        "print('Vocabulary size of the data: %d' % vocab_size)\n",
        "\n",
        "#Encoding the data\n",
        "trainX = text_encoder(tokenizer, X_train_n[0:], length)\n",
        "testX = text_encoder(tokenizer, X_test_n[0:], length)\n",
        "print(trainX.shape, testX.shape)\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_train_n)\n",
        "y_trainning_labeled = encoder.transform(y_train_n)\n",
        "y_testing_labeled = encoder.transform(y_test_n)\n",
        "\n",
        "num_classes = np.max(y_trainning_labeled) + 1\n",
        "y_trainning_labeled = utils.to_categorical(y_trainning_labeled, num_classes)\n",
        "y_testing_labeled = utils.to_categorical(y_testing_labeled, num_classes)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum document length: 1224\n",
            "Vocabulary size of the data: 102072\n",
            "(52460, 1224) (13217, 1224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIMikVb_H7pZ"
      },
      "source": [
        "#Splitting the cleaned data into train and validation 90/10 ratio \n",
        " \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train_n , X_val , y_train_n , y_val = train_test_split (trainX, y_trainning_labeled, test_size= 0.1,random_state=42)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52Oy6qtk5qnC"
      },
      "source": [
        "Creating model using Keras and implementing different layers \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKrwSjwOU8qh"
      },
      "source": [
        "Model Combination 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABgZWttkfibN"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100, input_length=length))\n",
        "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqDeKzcPOPEc"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFs0QGG4yms8",
        "outputId": "2b70f21d-09ef-49f5-cca0-2fb8e64d6250",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
        "history = model.fit(X_train_n, y_train_n,\n",
        "                    epochs=5,batch_size=50)  \n",
        "\n",
        "#save the model\n",
        "model.save('model.h5')"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "945/945 [==============================] - 104s 110ms/step - loss: 0.4073 - accuracy: 0.9759\n",
            "Epoch 2/5\n",
            "945/945 [==============================] - 104s 110ms/step - loss: 0.3662 - accuracy: 0.9798\n",
            "Epoch 3/5\n",
            "945/945 [==============================] - 104s 110ms/step - loss: 0.3962 - accuracy: 0.9816\n",
            "Epoch 4/5\n",
            "945/945 [==============================] - 103s 109ms/step - loss: 0.4450 - accuracy: 0.9825\n",
            "Epoch 5/5\n",
            "945/945 [==============================] - 102s 108ms/step - loss: 0.4137 - accuracy: 0.9836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBQd2BBjHu4E",
        "outputId": "d6eb69cf-87fe-4f68-84d3-f1dc3076b510",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model.evaluate(X_val, y_val,\n",
        "                       batch_size=32, verbose=1)\n",
        "print('Validation accuracy :', score[1])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "164/164 [==============================] - 1s 6ms/step - loss: 10.3832 - accuracy: 0.8111\n",
            "Validation accuracy : 0.8110941648483276\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykj_4HYWIbB9",
        "outputId": "af738f52-6344-4cb2-88f9-9481a9cf6ea5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Prediction on Test data\n",
        "score = model.evaluate(testX, y_testing_labeled)\n",
        "print('Test accuracy :', score[1])\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "414/414 [==============================] - 3s 6ms/step - loss: 19.5548 - accuracy: 0.6781\n",
            "Test accuracy : 0.6780661344528198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Axsn4qPNVDzI"
      },
      "source": [
        "Model Combination 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDYF2_zcVHTe",
        "outputId": "0b937f6f-1278-481e-8dbe-c75b89b1db73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100, input_length=length))\n",
        "model.add(Conv1D(filters=128, kernel_size=3,strides=2 ,activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "\n",
        "opt = keras.optimizers.Adamax(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "history = model.fit(X_train_n, y_train_n,\n",
        "                    epochs=5,batch_size=50) \n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "945/945 [==============================] - 51s 54ms/step - loss: 1.6020 - accuracy: 0.5264\n",
            "Epoch 2/5\n",
            "945/945 [==============================] - 51s 54ms/step - loss: 1.2532 - accuracy: 0.6405\n",
            "Epoch 3/5\n",
            "945/945 [==============================] - 51s 54ms/step - loss: 1.0993 - accuracy: 0.6903\n",
            "Epoch 4/5\n",
            "945/945 [==============================] - 51s 54ms/step - loss: 0.9515 - accuracy: 0.7337\n",
            "Epoch 5/5\n",
            "945/945 [==============================] - 51s 54ms/step - loss: 0.8383 - accuracy: 0.7795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDh4RQDQfAXa",
        "outputId": "5a5be785-f864-47fc-f2b3-18e5ff9bed5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model.evaluate(X_val, y_val,\n",
        "                       batch_size=32, verbose=1)\n",
        "print('Validation accuracy :', score[1])\n",
        "\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "164/164 [==============================] - 1s 6ms/step - loss: 0.8567 - accuracy: 0.7735\n",
            "Validation accuracy : 0.7735417485237122\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mvSLDtlfEZr",
        "outputId": "d82af4a4-dfd3-4c25-eb31-73455bb4f637",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Prediction on Test data\n",
        "score = model.evaluate(testX, y_testing_labeled)\n",
        "print('Test accuracy :', score[1])"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "414/414 [==============================] - 2s 6ms/step - loss: 1.0085 - accuracy: 0.6405\n",
            "Test accuracy : 0.6404630541801453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOIXBbHtfPr_"
      },
      "source": [
        "Model Combination 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFcYv___fPHm",
        "outputId": "5ae2c37e-86f2-4fbd-a24d-8e6eee3a1ecc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100, input_length=length))\n",
        "model.add(Conv1D(filters=64, kernel_size=3,strides=2 ,activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "opt = Adam(learning_rate=0.001)\n",
        "model.compile(loss='huber',optimizer=opt, metrics=['accuracy'])\n",
        "history = model.fit(X_train_n, y_train_n,\n",
        "                    epochs=5,batch_size=50) \n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "945/945 [==============================] - 99s 105ms/step - loss: 0.0085 - accuracy: 0.6433\n",
            "Epoch 2/5\n",
            "945/945 [==============================] - 101s 106ms/step - loss: 0.0039 - accuracy: 0.8463\n",
            "Epoch 3/5\n",
            "945/945 [==============================] - 101s 106ms/step - loss: 0.0025 - accuracy: 0.8997\n",
            "Epoch 4/5\n",
            "945/945 [==============================] - 101s 107ms/step - loss: 0.0019 - accuracy: 0.9234\n",
            "Epoch 5/5\n",
            "945/945 [==============================] - 102s 108ms/step - loss: 0.0015 - accuracy: 0.9405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzC1svdfk5bG",
        "outputId": "98768fdb-1e90-4f6b-f457-d2c5bc68550c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model.evaluate(X_val, y_val,\n",
        "                       batch_size=32, verbose=1)\n",
        "print('Validation accuracy :', score[1])\n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "164/164 [==============================] - 1s 5ms/step - loss: 0.0045 - accuracy: 0.8315\n",
            "Validation accuracy : 0.8314906358718872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke48nTrClBBN",
        "outputId": "50fa99ba-585d-414e-c0d0-2f6d56324ab9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Prediction on Test data\n",
        "score = model.evaluate(testX, y_testing_labeled)\n",
        "print('Test accuracy :', score[1])"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0080 - accuracy: 0.7067\n",
            "Test accuracy : 0.7066656351089478\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vttXMN_wlNnJ"
      },
      "source": [
        "Model Combination 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlBy6jjflM7U",
        "outputId": "2531529a-00e5-4a93-ff13-90f718c159ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100, input_length=length))\n",
        "model.add(Conv1D(filters=128, kernel_size=3,strides=2 ,activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "opt = Adam(learning_rate=0.001)\n",
        "model.compile(loss='huber',optimizer=opt, metrics=['accuracy'])\n",
        "history = model.fit(X_train_n, y_train_n,\n",
        "                    epochs=5,batch_size=50) \n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "945/945 [==============================] - 102s 108ms/step - loss: 0.0083 - accuracy: 0.6534\n",
            "Epoch 2/5\n",
            "945/945 [==============================] - 102s 108ms/step - loss: 0.0036 - accuracy: 0.8546\n",
            "Epoch 3/5\n",
            "945/945 [==============================] - 102s 108ms/step - loss: 0.0022 - accuracy: 0.9126\n",
            "Epoch 4/5\n",
            "945/945 [==============================] - 103s 109ms/step - loss: 0.0015 - accuracy: 0.9381\n",
            "Epoch 5/5\n",
            "945/945 [==============================] - 103s 109ms/step - loss: 0.0012 - accuracy: 0.9545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0cXjuTInyUS",
        "outputId": "c4f6897d-dbbe-49de-e011-675882edbc51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model.evaluate(X_val, y_val,\n",
        "                       batch_size=32, verbose=1)\n",
        "print('Validation accuracy :', score[1])\n"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "164/164 [==============================] - 1s 6ms/step - loss: 0.0044 - accuracy: 0.8324\n",
            "Validation accuracy : 0.8324437737464905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUMUXz9mn24v",
        "outputId": "294b3ccf-dd83-4e7e-f9f7-766a427f5558",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Prediction on Test data\n",
        "score = model.evaluate(testX, y_testing_labeled)\n",
        "print('Test accuracy :', score[1])"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0085 - accuracy: 0.7055\n",
            "Test accuracy : 0.7055307626724243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0yTIPQ5qRhJ"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100, input_length=length))\n",
        "model.add(Conv1D(filters=128, kernel_size=3,strides=2 ,activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1fFIcS9onHB",
        "outputId": "9b4653c2-ce85-4da0-acbb-7083c014af42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "opt = Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_hinge',optimizer=opt, metrics=['accuracy'])\n",
        "history = model.fit(X_train_n, y_train_n,\n",
        "                    epochs=5,batch_size=100) "
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "473/473 [==============================] - 58s 122ms/step - loss: 0.0594 - accuracy: 0.9690\n",
            "Epoch 2/5\n",
            "473/473 [==============================] - 57s 121ms/step - loss: 0.0504 - accuracy: 0.9729\n",
            "Epoch 3/5\n",
            "473/473 [==============================] - 57s 121ms/step - loss: 0.0451 - accuracy: 0.9759\n",
            "Epoch 4/5\n",
            "473/473 [==============================] - 57s 120ms/step - loss: 0.0417 - accuracy: 0.9773\n",
            "Epoch 5/5\n",
            "473/473 [==============================] - 58s 122ms/step - loss: 0.0386 - accuracy: 0.9789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZKJszvosYst",
        "outputId": "a2723444-d5fb-40fe-906f-2ec18aea50d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model.evaluate(X_val, y_val,\n",
        "                       batch_size=32, verbose=1)\n",
        "print('Validation accuracy :', score[1])\n"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "164/164 [==============================] - 1s 6ms/step - loss: 0.3926 - accuracy: 0.7791\n",
            "Validation accuracy : 0.7790697813034058\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEV1nOGksbAG",
        "outputId": "158edd55-9b86-45be-f390-1bfa2be7da13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Prediction on Test data\n",
        "score = model.evaluate(testX, y_testing_labeled)\n",
        "print('Test accuracy :', score[1])"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "414/414 [==============================] - 2s 5ms/step - loss: 0.5520 - accuracy: 0.7166\n",
            "Test accuracy : 0.7165771126747131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM8h98rQsmZN",
        "outputId": "6504ba14-8b27-4157-a79e-d68f0523bab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "para_grid= { 'alpha': [0.1,0.01,0.001,0.001],\n",
        "        'loss': ['huber','categorical_hinge','categorical_crossentropy'],\n",
        "        'optimizer':['adam','adammax','sgd'],\n",
        "        'dropout': [0.5, 0.4, 0.3, 0.2, 0.1, 0],\n",
        "        'batch_size':[50,75,100]\n",
        "          \n",
        "      }\n",
        "grid = GridSearchCV(estimator=model,  \n",
        "                    n_jobs=-1, \n",
        "                    verbose=1,\n",
        "                    cv=5,  \n",
        "                    param_grid=para_grid,\n",
        "                    scoring='categorical_crossentropy')\n",
        "\n",
        "grid_result = grid.fit(trainX,y_trainning_labeled )"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[0;34m(scoring)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSCORERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'categorical_crossentropy'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-138-61f69d76a3ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                     scoring='categorical_crossentropy')\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_trainning_labeled\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         scorers, self.multimetric_ = _check_multimetric_scoring(\n\u001b[0;32m--> 629\u001b[0;31m             self.estimator, scoring=self.scoring)\n\u001b[0m\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultimetric_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_check_multimetric_scoring\u001b[0;34m(estimator, scoring)\u001b[0m\n\u001b[1;32m    471\u001b[0m     if callable(scoring) or scoring is None or isinstance(scoring,\n\u001b[1;32m    472\u001b[0m                                                           str):\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0mscorers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    401\u001b[0m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;31m# Heuristic to ensure user has not passed a metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[0;34m(scoring)\u001b[0m\n\u001b[1;32m    361\u001b[0m             raise ValueError('%r is not a valid scoring value. '\n\u001b[1;32m    362\u001b[0m                              \u001b[0;34m'Use sorted(sklearn.metrics.SCORERS.keys()) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m                              'to get valid options.' % scoring)\n\u001b[0m\u001b[1;32m    364\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 'categorical_crossentropy' is not a valid scoring value. Use sorted(sklearn.metrics.SCORERS.keys()) to get valid options."
          ]
        }
      ]
    }
  ]
}
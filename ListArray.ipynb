{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ListArray.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPYnQCETYvDG61BlnkgzKok",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanikaKanu90/notebook/blob/master/ListArray.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb9BKFrTd4Jt",
        "outputId": "037f34c0-6b8d-4703-9468-cdbf026aa08e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "import sys\n",
        "x = ['1',2]\n",
        "\n",
        "for i, arg in enumerate(x):\n",
        "        print(f\"Argument {i:6}: {arg}\")\n",
        "        print(\"Number of arguments:\", len(sys.argv))\n",
        "\n",
        "acl = ':   '+x[0]+': '  +sys.argv[1]+'  :'+ sys.argv[2]\n",
        "acl\n",
        "\n",
        "print('Argument List:', str(sys.argv)) \n",
        "print(type(x))  \n",
        "\n",
        "y= [1,2,3]  # list\n",
        "print(type(y)) \n",
        "\n",
        "\n",
        "#array\n",
        "import numpy as np\n",
        "\n",
        "a = np.ones((3,2))        # a 2D array with 3 rows, 2 columns, filled with ones\n",
        "b = np.array([1,2,3])     # a 1D array initialised using a list [1,2,3]\n",
        "c = np.linspace(2,3,10)  # an array with 100 points beteen (and including) 2 and 3\n",
        "\n",
        "print(a,b,c)\n",
        "print(a*1.5)  # all elements of a times 1.5\n",
        "print(a.T+b)  # b added to the transpose of a\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Argument      0: 1\n",
            "Number of arguments: 3\n",
            "Argument      1: 2\n",
            "Number of arguments: 3\n",
            "Argument List: ['/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py', '-f', '/root/.local/share/jupyter/runtime/kernel-e03ce80b-f818-4841-8e31-1686245395d5.json']\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "[[1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]] [1 2 3] [2.         2.11111111 2.22222222 2.33333333 2.44444444 2.55555556\n",
            " 2.66666667 2.77777778 2.88888889 3.        ]\n",
            "[[1.5 1.5]\n",
            " [1.5 1.5]\n",
            " [1.5 1.5]]\n",
            "[[2. 3. 4.]\n",
            " [2. 3. 4.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6R1W1h4xAtB",
        "outputId": "4a55791b-d7b8-4272-849b-ad11116bfeb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "text = np.random.randint(1, 1000,size=(100, 10))\n",
        "text"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[769, 308, 751, 923, 233, 126, 554, 740, 154, 384],\n",
              "       [300, 534, 342, 496, 568, 817, 289, 942, 837, 642],\n",
              "       [495, 557, 704, 621, 962, 795, 261, 486, 525, 533],\n",
              "       [175, 698,  83, 422, 746, 938, 638, 187, 430, 902],\n",
              "       [185, 369, 611, 844, 805,   9, 745, 130, 172,  92],\n",
              "       [ 27,  20, 658, 584, 232, 432, 485, 345, 487, 429],\n",
              "       [932, 760, 111, 449, 176, 811, 593, 945, 552, 251],\n",
              "       [701, 767, 146, 658,  57, 678, 549, 557, 866, 492],\n",
              "       [272, 462, 148, 840, 528, 612, 583, 117, 311, 791],\n",
              "       [827,  21, 792, 108, 243,  45, 914, 109, 794, 964],\n",
              "       [683, 260,  36, 761, 976, 267, 200, 782, 256, 861],\n",
              "       [233, 628, 527, 195, 349, 561, 377, 196, 709, 392],\n",
              "       [412, 473, 355, 414, 365, 660,  26, 985, 142, 287],\n",
              "       [159,  45, 790, 798, 503,  42, 361, 268, 248, 483],\n",
              "       [229, 472, 591,   1, 743, 500, 617,  31, 989, 549],\n",
              "       [216, 391, 974, 534, 993, 937, 414, 403, 843,  96],\n",
              "       [712,  14, 693, 154,  86, 939, 520, 973, 442, 398],\n",
              "       [130, 599, 289, 687, 480, 884,  65, 890,  36, 485],\n",
              "       [321, 100, 932, 280, 160, 459, 444, 601, 434, 593],\n",
              "       [338, 274, 202, 397, 165, 991, 273, 753, 156, 684],\n",
              "       [345, 481, 227, 735, 311, 220,  93, 165, 376, 180],\n",
              "       [ 99, 523, 860, 739, 671, 522, 550,  58, 364, 494],\n",
              "       [642, 453, 936, 286, 653, 972, 874, 806, 952, 945],\n",
              "       [330, 889, 291, 227, 382, 705,  61, 237, 324, 288],\n",
              "       [238, 354, 127, 133, 863, 820,  56, 970, 735, 277],\n",
              "       [297, 718, 686, 167, 237, 240,  26, 369, 760, 113],\n",
              "       [896, 403, 839, 873, 483, 996, 773, 958, 320, 799],\n",
              "       [618, 560, 966, 695, 643, 887, 661, 285, 921, 639],\n",
              "       [714, 902, 497, 834, 873, 668, 746, 320, 792, 359],\n",
              "       [256,  63, 506, 865,  12,  15, 206, 438, 164, 463],\n",
              "       [325, 739, 133, 746, 360, 172, 992, 282, 675, 723],\n",
              "       [454, 750, 241, 510, 842, 514, 671, 709, 808, 566],\n",
              "       [671,  99, 953, 279, 408, 567, 523, 129, 391, 389],\n",
              "       [ 34, 413, 363, 667, 780, 397, 875, 256,  74, 148],\n",
              "       [ 68, 652, 225, 198, 704, 648, 141, 493, 796, 336],\n",
              "       [ 79, 757, 662, 716, 804,  97, 504, 503, 341, 504],\n",
              "       [667, 463, 243, 398, 843,  20, 817, 816, 844, 819],\n",
              "       [564, 632, 647, 344, 595,  80, 328, 190, 931, 655],\n",
              "       [670, 325, 436,  37, 446,  54, 252, 956, 921, 660],\n",
              "       [935, 396, 274,  45,  50,  41, 802, 781, 566, 281],\n",
              "       [447, 696, 565, 695,   4, 621, 938, 139, 342, 888],\n",
              "       [871, 501, 881, 564, 854, 198, 651, 113, 878, 821],\n",
              "       [922, 528, 475, 208, 940, 322, 135, 486, 635,  96],\n",
              "       [576,  55, 599, 409, 663, 742, 411, 511, 730, 912],\n",
              "       [961, 402, 834, 232,  20, 124, 682, 670, 903, 587],\n",
              "       [416,  28, 852, 749,  44, 797, 558, 178, 707, 859],\n",
              "       [898, 192, 664, 213, 171, 490, 325, 876, 895, 717],\n",
              "       [630, 664, 754, 983, 991,  33, 510, 292, 574, 556],\n",
              "       [579,  73, 783, 145, 591, 239,  85,   6,  71, 258],\n",
              "       [894, 784, 227, 239, 919, 215,  27, 636, 132, 458],\n",
              "       [503, 241, 330, 230, 781, 595, 489, 749,  64, 557],\n",
              "       [ 50, 157, 839, 895, 310, 294, 967, 808, 985, 780],\n",
              "       [ 58, 657, 522, 187, 858, 919, 220, 629, 711, 320],\n",
              "       [536, 958, 543, 893, 711, 951, 836,   2, 895,  21],\n",
              "       [317, 750, 727, 488, 227, 371, 522, 552,  18, 639],\n",
              "       [101, 424, 931, 145, 332,  77, 422, 938, 197, 981],\n",
              "       [913, 675, 637, 597, 551, 916, 754, 303, 872,  84],\n",
              "       [ 21, 821, 398, 420, 562, 948, 343, 417, 455, 944],\n",
              "       [730, 360, 833, 331, 719, 655, 129, 615, 971, 886],\n",
              "       [481,  44, 664, 634, 477, 779, 580,  77,  31, 473],\n",
              "       [220, 821, 878, 925, 982, 828,  33, 733, 284, 563],\n",
              "       [467, 824, 838, 625, 452,  35, 852, 292,  59, 745],\n",
              "       [755, 808, 587, 202, 958, 934, 299,  36, 578, 958],\n",
              "       [867,  42, 807, 777, 632, 491, 438, 148, 880, 689],\n",
              "       [898, 216, 456, 908, 317,  23, 454, 516, 879, 865],\n",
              "       [335, 567, 706, 159, 675, 394, 399, 668, 744, 333],\n",
              "       [452, 693, 881, 122, 933, 285, 717, 902, 378, 943],\n",
              "       [226,  70, 921, 212, 318, 384, 665, 912, 288, 555],\n",
              "       [703, 159, 424, 200, 236, 520,  22, 377, 369, 399],\n",
              "       [492, 611, 896, 934,  93, 163, 164, 862, 869, 609],\n",
              "       [115, 723, 753, 207, 930, 443,  89, 189, 116, 335],\n",
              "       [367, 639, 695, 854, 953,  82, 405, 435, 404, 285],\n",
              "       [839, 416, 991, 493, 921, 692, 725, 275, 106, 229],\n",
              "       [626, 343, 829, 145, 306, 283, 510, 535, 246, 355],\n",
              "       [591, 324, 160,  20, 934,  15, 428, 665,  65, 243],\n",
              "       [292, 135, 858, 271, 926, 188, 109, 720,  63, 392],\n",
              "       [657, 658, 636, 614, 100, 547, 428,  72, 974, 758],\n",
              "       [314, 379, 442, 671, 566, 836, 107, 691, 974, 942],\n",
              "       [ 35, 577, 347, 406, 655, 473, 724, 933, 608, 699],\n",
              "       [477, 184, 721, 668, 517, 549, 101, 836, 503, 455],\n",
              "       [917, 987, 295, 426, 483, 771, 854, 201, 293, 273],\n",
              "       [626, 157, 134, 835, 708, 261, 563, 207, 832, 989],\n",
              "       [559, 959, 482, 388, 166, 629, 838, 848, 554, 456],\n",
              "       [506, 582, 305, 518, 587, 709, 948, 789, 772,  56],\n",
              "       [991, 462, 211, 596, 293, 211, 855, 579, 163, 811],\n",
              "       [365, 215, 195, 524, 351, 967,  82, 235, 786, 804],\n",
              "       [193, 357,  36, 484, 666, 832, 762, 687,  66, 707],\n",
              "       [915, 836, 846, 131,  74, 971, 217, 398, 821, 753],\n",
              "       [ 59, 291, 862, 941, 179, 504, 206, 702, 901,  20],\n",
              "       [479, 772, 940, 351,   2, 991, 750, 161, 565, 223],\n",
              "       [616, 254, 592, 301, 635, 259, 139, 187, 103, 507],\n",
              "       [611, 549, 473,  89, 527, 368, 386, 624, 697, 978],\n",
              "       [854,  42, 458, 925, 320, 401, 353, 212, 136, 373],\n",
              "       [769, 881, 391, 715, 242, 346, 384, 718, 525, 991],\n",
              "       [340, 318,  98, 410, 188,   9, 388,  58, 914, 392],\n",
              "       [  3, 880, 925,  34, 982, 637, 235, 589, 427, 365],\n",
              "       [160, 447, 546, 477, 771,  38, 994, 294, 242, 822],\n",
              "       [ 68, 300, 185, 791, 129,  84, 701, 407, 227, 792],\n",
              "       [203, 860, 135, 722, 414, 674, 213, 740, 219, 148],\n",
              "       [417, 341, 979, 442, 122, 433, 821, 566, 854, 433]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFtrMTxYzkN7",
        "outputId": "c0fbc62b-4c03-4d2c-9e0b-2ff0771c102d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        }
      },
      "source": [
        "answers = np.random.randint(0, 1,size=(50, 10))  #one-hot encoded, not integers\n",
        "answers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mwozaa4D37xl",
        "outputId": "d916e08a-85fb-4c0c-d6eb-49095446521f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from keras import layers \n",
        "from keras import Input\n",
        "\n",
        "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
        "print(text_input)\n",
        "\n",
        "embedded_text = layers.Embedding(64, 1000)(text_input) #fits input:text_input into sequence of vectors of fixed size 64\n",
        "embedded_text"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"text_2:0\", shape=(None, None), dtype=int32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'embedding_2/embedding_lookup/Identity_1:0' shape=(None, None, 1000) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}